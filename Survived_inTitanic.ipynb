{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "RDSTPVeGuTsg",
    "outputId": "88a6583f-0743-4c85-e2ff-044c6b903917"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Making DataFrame\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df_test = pd.read_csv('titanic_test.csv')\n",
    "df_full = [df, df_test]\n",
    "\n",
    "# Determine the FamilySize\n",
    "for dataset in df_full:\n",
    "  dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "# Determine isAlone or not\n",
    "for dataset in df_full:\n",
    "  dataset['isAlone'] = 0\n",
    "  dataset.loc[dataset['FamilySize']==1, 'isAlone'] = 1\n",
    "\n",
    "# Replace empty data with mode in Embarked\n",
    "for dataset in df_full:\n",
    "    mode = dataset['Embarked'].mode()\n",
    "    dataset['Embarked'] = df['Embarked'].fillna(mode)\n",
    "\n",
    "# Replace empty data with mean in Fare. Then making 'CategoricalFare' column\n",
    "for dataset in df_full:\n",
    "  mean = dataset['Fare'].mean()\n",
    "  dataset['Fare'] = dataset['Fare'].fillna(mean)\n",
    "  dataset['CategoricalFare'] = pd.qcut(dataset['Fare'], 4)\n",
    "\n",
    "# Fill the empty data in 'Age' column and making 'CategoricalAge' column  \n",
    "for dataset in df_full:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    dataset['CategoricalAge'] = pd.cut(dataset['Age'], 5)\n",
    "\n",
    "# Take the prefix for each values in 'Name' column and making 'Title' column\n",
    "def get_title(name):\n",
    "\ttitle_search = re.search('([A-Za-z]+)\\.', name)\n",
    "\tif title_search:\n",
    "\t\treturn title_search.group(1)\n",
    "\treturn \"\"\n",
    "for dataset in df_full:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "\n",
    "# Preprocessing data in 'Title' column\n",
    "for dataset in df_full:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "                                                 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs') \n",
    "\n",
    "# Feature Selection\n",
    "drop_elements = ['PassengerId', 'Name', 'Age', 'Fare', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'FamilySize']\n",
    "df = df.drop(drop_elements, axis = 1)\n",
    "df_test = df_test.drop(drop_elements, axis = 1)   \n",
    "\n",
    "# Column Partition \n",
    "df = pd.get_dummies(df)\n",
    "df_test = pd.get_dummies(df_test)\n",
    "\n",
    "# Choosing the best machine learning model \n",
    "classifiers = [KNeighborsClassifier(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(),AdaBoostClassifier(),\\\n",
    "               GradientBoostingClassifier(), GaussianNB(), LinearDiscriminantAnalysis(), QuadraticDiscriminantAnalysis(),\\\n",
    "               LogisticRegression()]\n",
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "\n",
    "acc = []\n",
    "for cls in classifiers:\n",
    "    cls.fit(X_train, y_train)\n",
    "    y_pred = cls.predict(X_test)\n",
    "    a = accuracy_score(y_test, y_pred)\n",
    "    acc.append(a)\n",
    "\n",
    "data = {'Classifier': ['KNeighborsClassifier', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier',\\\n",
    "                       'AdaBoostClassifier', 'GradientBoostingClassifier', 'GaussianNB', 'LinearDiscriminantAnalysis',\\\n",
    "                       'QuadraticDiscriminantAnalysis', 'LogisticRegression'], 'Accuracy': acc}\n",
    "df_class_acc = pd.DataFrame(data)\n",
    "\n",
    "#Make a Plot\n",
    "sns.barplot(x = 'Accuracy', y = 'Classifier', data = df_class_acc)\n",
    "plt.show()\n",
    "\n",
    "#Hyperparameter Tuning\n",
    "tree = DecisionTreeClassifier()\n",
    "param_grid = {'criterion' : ['gini', 'entropy'], 'max_depth':list(range(1,11)),'min_samples_split':list(range(1,11)),'max_features': list(range(1, 11)),'min_samples_leaf': list(range(1, 11))}\n",
    "gscv = GridSearchCV(tree, param_grid=param_grid)\n",
    "gscv.fit(X_train, y_train)\n",
    "gscv.best_params_\n",
    "\n",
    "# Make machine learning model based on best_params_\n",
    "tree = DecisionTreeClassifier(criterion = 'entropy',max_depth = 5,max_features = 10,min_samples_leaf = 5,min_samples_split = 4)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.score(X_test,y_test)\n",
    "\n",
    "# Predict for the titanic_test\n",
    "y_pred = tree.predict(df_test)\n",
    "\n",
    "# Make DataFrame for submission\n",
    "submission = pd.read_csv('titanic_test.csv')\n",
    "submission['Survived'] = y_pred\n",
    "submission = submission.drop(submission.iloc[:, 1:11], axis = 1)\n",
    "\n",
    "# Save to csv\n",
    "submission.to_csv('submissionDTC2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Survived_inTitanic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
